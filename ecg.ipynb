{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the ECG Data to converted the .atr and .hea to image of 112*112 pixel in greyscale"
      ],
      "metadata": {
        "id": "-CCqpLx6SpP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT required Library"
      ],
      "metadata": {
        "id": "gVawel4OTsw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wfdb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pywt\n",
        "from scipy.signal import butter, filtfilt, find_peaks\n",
        "from PIL import Image"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SHDDCYSkTy6h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove baseline drift from ecg Signal\n",
        "This function is designed to remove low-frequency components or \"baseline drift\" from an ECG signal using wavelet decomposition"
      ],
      "metadata": {
        "id": "n-ckK9KWT_td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_baseline_drift(signal, wavelet=\"db6\", level=9):\n",
        "    coeff = pywt.wavedec(signal, wavelet, level=level)\n",
        "    coeff[0] = np.zeros_like(coeff[0])  # remove low-frequency drift\n",
        "    return pywt.waverec(coeff, wavelet)"
      ],
      "metadata": {
        "id": "emwjBtgnT1nb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5th order Bandpass Filter"
      ],
      "metadata": {
        "id": "JYknzOx0UNeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bandpass_filter(signal, low_freq, high_freq, fs, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    low = low_freq / nyquist\n",
        "    high = high_freq / nyquist\n",
        "    b, a = butter(order, [low, high], btype=\"band\")\n",
        "    return filtfilt(b, a, signal)"
      ],
      "metadata": {
        "id": "mPUzDzm0UOA9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect R peak"
      ],
      "metadata": {
        "id": "7eMjEso8Ukg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_r_peaks(ecg_signal, fs=500):\n",
        "    \"\"\"\n",
        "    Detect only R-peaks, avoiding T-peaks.\n",
        "    \"\"\"\n",
        "    # 1. Initial peak detection\n",
        "    distance = int(0.2 * fs)  # at least 200 ms apart\n",
        "    raw_peaks, _ = find_peaks(ecg_signal, distance=distance, height=np.mean(ecg_signal) + 0.5*np.std(ecg_signal))\n",
        "\n",
        "    # 2. Refine: keep peaks with sharp slope (R-peaks are steep)\n",
        "    r_peaks = []\n",
        "    for idx in raw_peaks:\n",
        "        # local slope around the peak\n",
        "        left = max(0, idx-5)\n",
        "        right = min(len(ecg_signal)-1, idx+5)\n",
        "        slope = np.max(np.diff(ecg_signal[left:right]))\n",
        "\n",
        "        # local amplitude\n",
        "        amp = ecg_signal[idx]\n",
        "\n",
        "        # Apply slope and amplitude threshold\n",
        "        if slope > 0.5*np.std(ecg_signal) and amp > 0.5*np.max(ecg_signal):\n",
        "            r_peaks.append(idx)\n",
        "\n",
        "    return np.array(r_peaks)"
      ],
      "metadata": {
        "id": "DFCgdQNGUdfC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load ECG Data"
      ],
      "metadata": {
        "id": "Y3I83_12UdHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ecg_data(record_path):\n",
        "    record = wfdb.rdrecord(record_path)\n",
        "    ecg_signal = record.p_signal[:, 0]  # first channel\n",
        "\n",
        "    # filtering\n",
        "    ecg_signal = remove_baseline_drift(ecg_signal)\n",
        "    ecg_signal = bandpass_filter(ecg_signal, 0.5, 40, fs=500)\n",
        "\n",
        "    # detect R-peaks\n",
        "    r_peaks = detect_r_peaks(ecg_signal, fs=500)\n",
        "    return ecg_signal, r_peaks"
      ],
      "metadata": {
        "id": "MWiSUMs5UqQe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Generation"
      ],
      "metadata": {
        "id": "MMlFQQwcU1XM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def save_beat_images(ecg_signal, r_peaks, record_name, person_id, output_dir, fs=500):\n",
        "    margin = int(0.2 * fs)  # 200 ms = 100 samples at 500 Hz\n",
        "\n",
        "    # Directories for single, two, three\n",
        "    single_dir = os.path.join(output_dir, \"Single_Beat\", person_id)\n",
        "    two_dir = os.path.join(output_dir, \"Two_Beats\", person_id)\n",
        "    three_dir = os.path.join(output_dir, \"Three_Beats\", person_id)\n",
        "    os.makedirs(single_dir, exist_ok=True)\n",
        "    os.makedirs(two_dir, exist_ok=True)\n",
        "    os.makedirs(three_dir, exist_ok=True)\n",
        "\n",
        "    for i in range(len(r_peaks) - 3):  # ensure enough future beats\n",
        "        # --- Single Beat ---\n",
        "        start = max(r_peaks[i] - margin, 0)\n",
        "        end = min(r_peaks[i] + margin, len(ecg_signal))\n",
        "        single = ecg_signal[start:end]\n",
        "\n",
        "        plt.figure(figsize=(2,2))  # square figure\n",
        "        plt.plot(single, color=\"black\", linewidth=1)\n",
        "        plt.axis(\"off\")\n",
        "        temp_path = os.path.join(\"C:\\\\ecg_new\\\\t_img\", \"temp.png\")\n",
        "        plt.savefig(temp_path, bbox_inches=\"tight\", pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "        # Convert to grayscale 112x112\n",
        "        img = Image.open(temp_path).convert(\"L\")\n",
        "        img = img.resize((112,112))\n",
        "        img.save(os.path.join(single_dir, f\"{record_name}_single_{i}.png\"))\n",
        "        os.remove(temp_path)  # clean temp\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # --- Two Beats ---\n",
        "        end_two = min(r_peaks[i+1] + margin, len(ecg_signal))\n",
        "        two_beats = ecg_signal[start:end_two]\n",
        "\n",
        "        plt.figure(figsize=(2,2))  # square figure\n",
        "        plt.plot(two_beats, color=\"black\", linewidth=1)\n",
        "        plt.axis(\"off\")\n",
        "        temp_path = os.path.join(\"C:\\\\ecg_new\\\\t_img\", \"temp.png\")\n",
        "        plt.savefig(temp_path, bbox_inches=\"tight\", pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "        # Convert to grayscale 112x112\n",
        "        img = Image.open(temp_path).convert(\"L\")\n",
        "        img = img.resize((112,112))\n",
        "        img.save(os.path.join(two_dir, f\"{record_name}_two_{i}.png\"))\n",
        "        os.remove(temp_path)  # clean temp\n",
        "\n",
        "        # --- Three Beats ---\n",
        "        end_three = min(r_peaks[i+2] + margin, len(ecg_signal))\n",
        "        three_beats = ecg_signal[start:end_three]\n",
        "\n",
        "        plt.figure(figsize=(2,2))  # square figure\n",
        "        plt.plot(three_beats, color=\"black\", linewidth=1)\n",
        "        plt.axis(\"off\")\n",
        "        temp_path = os.path.join(\"C:\\\\ecg_new\\\\t_img\", \"temp.png\")\n",
        "        plt.savefig(temp_path, bbox_inches=\"tight\", pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "        # Convert to grayscale 112x112\n",
        "        img = Image.open(temp_path).convert(\"L\")\n",
        "        img = img.resize((112,112))\n",
        "        img.save(os.path.join(three_dir, f\"{record_name}_three_{i}.png\"))\n",
        "        os.remove(temp_path)  # clean temp\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ------------------ Runner ------------------\n",
        "\n",
        "base_directory = \"C:\\\\ecg_new\\\\ecg-id-database-1.0.0\"\n",
        "output_directory = \"C:\\\\ecg_new\\\\ecg_grayscale_images\"\n",
        "\n",
        "for p in range(1, 91):\n",
        "    person_id = f\"Person_{p:02d}\"\n",
        "    person_path = os.path.join(base_directory, person_id)\n",
        "\n",
        "    if not os.path.exists(person_path):\n",
        "        print(f\"Skipping {person_id} (folder not found)\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing {person_id}...\")\n",
        "\n",
        "    for record_file in os.listdir(person_path):\n",
        "        if record_file.endswith(\".dat\"):\n",
        "            record_base = record_file[:-4]\n",
        "            record_path = os.path.join(person_path, record_base)\n",
        "\n",
        "            try:\n",
        "                ecg_signal, r_peaks = load_ecg_data(record_path)\n",
        "                save_beat_images(ecg_signal, r_peaks, record_base, person_id, output_directory)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {record_path}: {e}\")\n",
        "\n",
        "print(\"✅ Image databases created: Single_Beat, Two_Beats, Three_Beats\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ycT1tmS6U2Q5",
        "outputId": "b381a032-ec21-40c5-bce0-53e5750d8699"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping Person_01 (folder not found)\n",
            "Skipping Person_02 (folder not found)\n",
            "Skipping Person_03 (folder not found)\n",
            "Skipping Person_04 (folder not found)\n",
            "Skipping Person_05 (folder not found)\n",
            "Skipping Person_06 (folder not found)\n",
            "Skipping Person_07 (folder not found)\n",
            "Skipping Person_08 (folder not found)\n",
            "Skipping Person_09 (folder not found)\n",
            "Skipping Person_10 (folder not found)\n",
            "Skipping Person_11 (folder not found)\n",
            "Skipping Person_12 (folder not found)\n",
            "Skipping Person_13 (folder not found)\n",
            "Skipping Person_14 (folder not found)\n",
            "Skipping Person_15 (folder not found)\n",
            "Skipping Person_16 (folder not found)\n",
            "Skipping Person_17 (folder not found)\n",
            "Skipping Person_18 (folder not found)\n",
            "Skipping Person_19 (folder not found)\n",
            "Skipping Person_20 (folder not found)\n",
            "Skipping Person_21 (folder not found)\n",
            "Skipping Person_22 (folder not found)\n",
            "Skipping Person_23 (folder not found)\n",
            "Skipping Person_24 (folder not found)\n",
            "Skipping Person_25 (folder not found)\n",
            "Skipping Person_26 (folder not found)\n",
            "Skipping Person_27 (folder not found)\n",
            "Skipping Person_28 (folder not found)\n",
            "Skipping Person_29 (folder not found)\n",
            "Skipping Person_30 (folder not found)\n",
            "Skipping Person_31 (folder not found)\n",
            "Skipping Person_32 (folder not found)\n",
            "Skipping Person_33 (folder not found)\n",
            "Skipping Person_34 (folder not found)\n",
            "Skipping Person_35 (folder not found)\n",
            "Skipping Person_36 (folder not found)\n",
            "Skipping Person_37 (folder not found)\n",
            "Skipping Person_38 (folder not found)\n",
            "Skipping Person_39 (folder not found)\n",
            "Skipping Person_40 (folder not found)\n",
            "Skipping Person_41 (folder not found)\n",
            "Skipping Person_42 (folder not found)\n",
            "Skipping Person_43 (folder not found)\n",
            "Skipping Person_44 (folder not found)\n",
            "Skipping Person_45 (folder not found)\n",
            "Skipping Person_46 (folder not found)\n",
            "Skipping Person_47 (folder not found)\n",
            "Skipping Person_48 (folder not found)\n",
            "Skipping Person_49 (folder not found)\n",
            "Skipping Person_50 (folder not found)\n",
            "Skipping Person_51 (folder not found)\n",
            "Skipping Person_52 (folder not found)\n",
            "Skipping Person_53 (folder not found)\n",
            "Skipping Person_54 (folder not found)\n",
            "Skipping Person_55 (folder not found)\n",
            "Skipping Person_56 (folder not found)\n",
            "Skipping Person_57 (folder not found)\n",
            "Skipping Person_58 (folder not found)\n",
            "Skipping Person_59 (folder not found)\n",
            "Skipping Person_60 (folder not found)\n",
            "Skipping Person_61 (folder not found)\n",
            "Skipping Person_62 (folder not found)\n",
            "Skipping Person_63 (folder not found)\n",
            "Skipping Person_64 (folder not found)\n",
            "Skipping Person_65 (folder not found)\n",
            "Skipping Person_66 (folder not found)\n",
            "Skipping Person_67 (folder not found)\n",
            "Skipping Person_68 (folder not found)\n",
            "Skipping Person_69 (folder not found)\n",
            "Skipping Person_70 (folder not found)\n",
            "Skipping Person_71 (folder not found)\n",
            "Skipping Person_72 (folder not found)\n",
            "Skipping Person_73 (folder not found)\n",
            "Skipping Person_74 (folder not found)\n",
            "Skipping Person_75 (folder not found)\n",
            "Skipping Person_76 (folder not found)\n",
            "Skipping Person_77 (folder not found)\n",
            "Skipping Person_78 (folder not found)\n",
            "Skipping Person_79 (folder not found)\n",
            "Skipping Person_80 (folder not found)\n",
            "Skipping Person_81 (folder not found)\n",
            "Skipping Person_82 (folder not found)\n",
            "Skipping Person_83 (folder not found)\n",
            "Skipping Person_84 (folder not found)\n",
            "Skipping Person_85 (folder not found)\n",
            "Skipping Person_86 (folder not found)\n",
            "Skipping Person_87 (folder not found)\n",
            "Skipping Person_88 (folder not found)\n",
            "Skipping Person_89 (folder not found)\n",
            "Skipping Person_90 (folder not found)\n",
            "✅ Image databases created: Single_Beat, Two_Beats, Three_Beats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "MRU0giIjeL2s",
        "outputId": "29aab1c5-478d-45ab-f635-f41a2c701206"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Database Handling and Model Training\n"
      ],
      "metadata": {
        "id": "HextP33DV5xH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Required library"
      ],
      "metadata": {
        "id": "HacmqBJJV_k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1c60lp5sWANp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "activation function"
      ],
      "metadata": {
        "id": "UmHWzaRaXBkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def swish_activation(x):\n",
        "    \"\"\"Swish activation function: x * sigmoid(x)\"\"\"\n",
        "    return x * tf.nn.sigmoid(x)\n",
        "\n",
        "# Register custom activation\n",
        "tf.keras.utils.get_custom_objects().update({'swish_activation': swish_activation})"
      ],
      "metadata": {
        "id": "8RioFV-ZXGpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_activation(x):\n",
        "    return 1.0 / (1.0 + K.pow(10.0, -x))\n",
        "\n",
        "tf.keras.utils.get_custom_objects().update({'custom_activation': custom_activation})"
      ],
      "metadata": {
        "id": "RiJ1I7HcZb3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation"
      ],
      "metadata": {
        "id": "m2G5pkaiZdsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_balanced_pairs(data_dir, img_size=(112,112), pairs_per_person=200):\n",
        "    persons = [os.path.join(data_dir, p) for p in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, p))]\n",
        "    images = {}\n",
        "\n",
        "    # Load and preprocess images\n",
        "    for person in persons:\n",
        "        person_id = os.path.basename(person)\n",
        "        imgs = []\n",
        "        files = [f for f in os.listdir(person) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        for file in files:\n",
        "            img_path = os.path.join(person, file)\n",
        "            try:\n",
        "                img = load_img(img_path, target_size=img_size, color_mode='grayscale')\n",
        "                img = img_to_array(img) / 255.0\n",
        "                # Add slight noise for data augmentation\n",
        "                img = img + np.random.normal(0, 0.01, img.shape)\n",
        "                img = np.clip(img, 0, 1)\n",
        "                imgs.append(img)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if len(imgs) >= 2:  # Only include persons with at least 2 images\n",
        "            images[person_id] = imgs\n",
        "\n",
        "    pairs, labels = [], []\n",
        "    person_ids = list(images.keys())\n",
        "\n",
        "    print(f\"Found {len(person_ids)} persons with sufficient images\")\n",
        "\n",
        "    # Create balanced positive pairs\n",
        "    positive_pairs = 0\n",
        "    for person_id in person_ids:\n",
        "        img_list = images[person_id]\n",
        "        # Create all possible positive pairs for this person\n",
        "        for i in range(len(img_list)):\n",
        "            for j in range(i+1, len(img_list)):\n",
        "                pairs.append([img_list[i], img_list[j]])\n",
        "                labels.append(1)\n",
        "                positive_pairs += 1\n",
        "\n",
        "                # Limit pairs per person to avoid class imbalance\n",
        "                if len([l for l in labels if l == 1]) >= pairs_per_person * len(person_ids):\n",
        "                    break\n",
        "            if len([l for l in labels if l == 1]) >= pairs_per_person * len(person_ids):\n",
        "                break\n",
        "\n",
        "    print(f\"Created {positive_pairs} positive pairs\")\n",
        "\n",
        "    # Create equal number of negative pairs\n",
        "    negative_pairs = 0\n",
        "    target_negative = positive_pairs\n",
        "\n",
        "    while negative_pairs < target_negative:\n",
        "        p1, p2 = random.sample(person_ids, 2)\n",
        "        img1 = random.choice(images[p1])\n",
        "        img2 = random.choice(images[p2])\n",
        "        pairs.append([img1, img2])\n",
        "        labels.append(0)\n",
        "        negative_pairs += 1\n",
        "\n",
        "    print(f\"Created {negative_pairs} negative pairs\")\n",
        "\n",
        "    # Shuffle the data\n",
        "    combined = list(zip(pairs, labels))\n",
        "    random.shuffle(combined)\n",
        "    pairs, labels = zip(*combined)\n",
        "\n",
        "    return np.array(pairs), np.array(labels)\n"
      ],
      "metadata": {
        "id": "343oId1bZeSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Siamese Network"
      ],
      "metadata": {
        "id": "3Ic12DsDaA-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_improved_base_network(input_shape=(112,112,1)):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "\n",
        "    # First Conv Block\n",
        "    x = layers.Conv2D(64, (7,7), strides=2, padding='same')(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(custom_activation)(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "\n",
        "    # Second Conv Block\n",
        "    x = layers.Conv2D(128, (5,5), strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(custom_activation)(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "\n",
        "    # Third Conv Block\n",
        "    x = layers.Conv2D(256, (3,3), strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(custom_activation)(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Fourth Conv Block\n",
        "    x = layers.Conv2D(512, (3,3), strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(custom_activation)(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Dense layers\n",
        "    x = layers.Dense(256)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(custom_activation)(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    # Final embedding layer\n",
        "    x = layers.Dense(128)(x)\n",
        "    x = layers.Lambda(lambda x: K.l2_normalize(x, axis=1))(x)  # L2 normalization\n",
        "\n",
        "    return models.Model(inp, x)"
      ],
      "metadata": {
        "id": "oIaeH3EXaBY8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function"
      ],
      "metadata": {
        "id": "oUsITID4a4MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def improved_contrastive_loss(y_true, y_pred, margin=1.0):\n",
        "    \"\"\"Improved contrastive loss with better gradient flow\"\"\"\n",
        "    square_pred = K.square(y_pred)\n",
        "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "\n",
        "    # Add small epsilon to prevent numerical instability\n",
        "    epsilon = 1e-6\n",
        "    loss = y_true * square_pred + (1 - y_true) * margin_square\n",
        "    return K.mean(loss + epsilon)\n",
        "\n",
        "def triplet_loss(y_true, y_pred, margin=0.2):\n",
        "    \"\"\"Alternative triplet loss\"\"\"\n",
        "    anchor, positive, negative = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]\n",
        "\n",
        "    pos_dist = K.sum(K.square(anchor - positive), axis=1)\n",
        "    neg_dist = K.sum(K.square(anchor - negative), axis=1)\n",
        "\n",
        "    loss = K.maximum(0.0, pos_dist - neg_dist + margin)\n",
        "    return K.mean(loss)"
      ],
      "metadata": {
        "id": "hcEWbUdtaxb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning rate scheduler"
      ],
      "metadata": {
        "id": "mbc2RyLvbBwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lr_scheduler():\n",
        "    def scheduler(epoch, lr):\n",
        "        if epoch < 5:\n",
        "            return lr\n",
        "        elif epoch < 15:\n",
        "            return lr * 0.95\n",
        "        else:\n",
        "            return lr * 0.9\n",
        "    return tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "ZOGDLlfobCKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Function"
      ],
      "metadata": {
        "id": "TVNjNJ6fb4X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_improved(dataset_path, save_name):\n",
        "    print(f\"\\nTraining improved model on dataset: {dataset_path}\")\n",
        "\n",
        "    # Create balanced pairs\n",
        "    pairs, labels = make_balanced_pairs(dataset_path, pairs_per_person=200)\n",
        "\n",
        "    print(f\"Total pairs: {len(pairs)}\")\n",
        "    print(f\"Positive pairs: {np.sum(labels)}\")\n",
        "    print(f\"Negative pairs: {len(labels) - np.sum(labels)}\")\n",
        "\n",
        "    X1, X2, y = pairs[:,0], pairs[:,1], labels\n",
        "\n",
        "    # Stratified split to maintain class balance\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(\n",
        "        X1, X2, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(f\"Training set - Positive: {np.sum(y_train)}, Negative: {len(y_train) - np.sum(y_train)}\")\n",
        "    print(f\"Test set - Positive: {np.sum(y_test)}, Negative: {len(y_test) - np.sum(y_test)}\")\n",
        "\n",
        "    # Build improved model\n",
        "    base_network = build_improved_base_network()\n",
        "\n",
        "    input_a = layers.Input(shape=(112,112,1))\n",
        "    input_b = layers.Input(shape=(112,112,1))\n",
        "    feat_a = base_network(input_a)\n",
        "    feat_b = base_network(input_b)\n",
        "\n",
        "    # Euclidean distance\n",
        "    distance = layers.Lambda(lambda tensors: K.sqrt(K.sum(K.square(tensors[0] - tensors[1]), axis=1, keepdims=True)))([feat_a, feat_b])\n",
        "\n",
        "    siamese_model = models.Model([input_a, input_b], distance)\n",
        "\n",
        "    # Compile with improved settings\n",
        "    optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "    siamese_model.compile(loss=improved_contrastive_loss, optimizer=optimizer)\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "        create_lr_scheduler(),\n",
        "        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss'),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-7)\n",
        "    ]\n",
        "\n",
        "    # Calculate class weights to handle any remaining imbalance\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "\n",
        "    print(\"Training model...\")\n",
        "    history = siamese_model.fit(\n",
        "        [X1_train, X2_train], y_train,\n",
        "        batch_size=16,  # Smaller batch size for better gradient updates\n",
        "        epochs=50,\n",
        "        validation_data=([X1_test, X2_test], y_test),\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weight_dict,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Save model\n",
        "    siamese_model.save(f\"{save_name}_improved.h5\")\n",
        "\n",
        "    # Predictions with optimal threshold\n",
        "    y_pred_dist = siamese_model.predict([X1_test, X2_test])\n",
        "\n",
        "    # Find optimal threshold using validation data\n",
        "    thresholds = np.arange(0.1, 2.0, 0.1)\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred_temp = (y_pred_dist < threshold).astype(\"int32\")\n",
        "        f1_temp = f1_score(y_test, y_pred_temp)\n",
        "        if f1_temp > best_f1:\n",
        "            best_f1 = f1_temp\n",
        "            best_threshold = threshold\n",
        "\n",
        "    print(f\"Optimal threshold: {best_threshold:.2f}\")\n",
        "\n",
        "    # Final predictions with optimal threshold\n",
        "    y_pred_class = (y_pred_dist < best_threshold).astype(\"int32\")\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(y_test, y_pred_class)\n",
        "    cm = confusion_matrix(y_test, y_pred_class)\n",
        "\n",
        "    if cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        sensitivity = tp / (tp + fn) if (tp+fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn+fp) > 0 else 0\n",
        "        precision = tp / (tp + fp) if (tp+fp) > 0 else 0\n",
        "    else:\n",
        "        sensitivity = specificity = precision = 0\n",
        "\n",
        "    f1 = f1_score(y_test, y_pred_class)\n",
        "\n",
        "    print(f\"\\n=== RESULTS ===\")\n",
        "    print(f\"Accuracy: {acc*100:.2f}%\")\n",
        "    print(f\"Sensitivity (Recall): {sensitivity*100:.2f}%\")\n",
        "    print(f\"Specificity: {specificity*100:.2f}%\")\n",
        "    print(f\"Precision: {precision*100:.2f}%\")\n",
        "    print(f\"F1 Score: {f1*100:.2f}%\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    # Enhanced plotting\n",
        "    plt.figure(figsize=(15,10))\n",
        "\n",
        "    # Loss curve\n",
        "    plt.subplot(2,3,1)\n",
        "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'{save_name} Loss Curve')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Distance distribution\n",
        "    plt.subplot(2,3,2)\n",
        "    pos_distances = y_pred_dist[y_test == 1].flatten()\n",
        "    neg_distances = y_pred_dist[y_test == 0].flatten()\n",
        "\n",
        "    plt.hist(pos_distances, bins=30, alpha=0.7, label='Same Person', color='green')\n",
        "    plt.hist(neg_distances, bins=30, alpha=0.7, label='Different Person', color='red')\n",
        "    plt.axvline(best_threshold, color='black', linestyle='--', label=f'Threshold: {best_threshold:.2f}')\n",
        "    plt.xlabel('Distance')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distance Distribution')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    plt.subplot(2,3,3)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(2)\n",
        "    plt.xticks(tick_marks, ['Different', 'Same'])\n",
        "    plt.yticks(tick_marks, ['Different', 'Same'])\n",
        "\n",
        "    # Add text annotations\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                    horizontalalignment=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\")\n",
        "\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "\n",
        "    # Metrics bar chart\n",
        "    plt.subplot(2,3,4)\n",
        "    metrics = ['Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1 Score']\n",
        "    values = [acc*100, sensitivity*100, specificity*100, precision*100, f1*100]\n",
        "    colors = ['blue', 'green', 'orange', 'red', 'purple']\n",
        "\n",
        "    bars = plt.bar(metrics, values, color=colors, alpha=0.7)\n",
        "    plt.ylabel('Percentage')\n",
        "    plt.title('Performance Metrics')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, value in zip(bars, values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "                f'{value:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "    # Learning rate curve\n",
        "    plt.subplot(2,3,5)\n",
        "    if 'lr' in history.history:\n",
        "        plt.plot(history.history['lr'], linewidth=2, color='purple')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Learning Rate')\n",
        "        plt.title('Learning Rate Schedule')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.yscale('log')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{save_name}_improved_results.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return siamese_model, history, best_threshold"
      ],
      "metadata": {
        "id": "TB442AZtb47C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main function"
      ],
      "metadata": {
        "id": "cM18uADKcq-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set random seeds for reproducibility\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "    random.seed(42)\n",
        "\n",
        "    base_path = \"C:\\\\ecg_new\\\\ecg_grayscale_images\"  # <-- change to your dataset base folder\n",
        "\n",
        "    for folder in [\"Single_Beat\", \"Two_Beats\", \"Three_Beats\"]:\n",
        "        dataset_path = os.path.join(base_path, folder)\n",
        "        if os.path.exists(dataset_path):\n",
        "            model, history, threshold = train_and_evaluate_improved(dataset_path, f\"siamese_{folder}\")\n",
        "            print(f\"\\nCompleted training for {folder}\")\n",
        "            print(\"=\"*50)\n",
        "        else:\n",
        "            print(f\"Dataset path not found: {dataset_path}\")"
      ],
      "metadata": {
        "id": "-u8xPWhpcrgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BjOikLuwdtiC"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}